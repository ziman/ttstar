{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TTstar benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, import our libraries...\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotnine as gg\n",
    "import sklearn.linear_model\n",
    "import statsmodels.formula.api as smf\n",
    "from plotnine import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ...and then load the data files\n",
    "\n",
    "#xs = pd.read_csv('benchmark-1490607733.csv')\n",
    "xs = pd.read_csv('benchmark-1491380156.csv')\n",
    "#xs = pd.read_csv('benchmark-1493248450.csv')\n",
    "#xs = pd.read_csv('benchmark-1493251003.csv')\n",
    "\n",
    "# this builds the column `config` as $STAGE-$FEATURES,\n",
    "# where each feature is the first letter of features enabled,\n",
    "# Example: ttstar-ivn\n",
    "\n",
    "xs['config'] = xs['stage'] + '-'\n",
    "for col in 'inference specialisation verification normalisation compilation'.split():\n",
    "    # the comparison to `True` is a hack to set NaNs to False\n",
    "    xs.loc[xs[col] == True, 'config'] += col[0]\n",
    "\n",
    "# Add a milliseconds column\n",
    "xs['runtime_ms'] = 1000 * xs['runtime']\n",
    "\n",
    "# Show the structure\n",
    "xs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How much time does erasure analysis take?\n",
    "\n",
    "The plot and the linear regression below give an answer:\n",
    "* typechecking alone takes about 2.5 milliseconds\n",
    "* erasure inference takes about 109 milliseconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ttstar\n",
    "ttstar = xs.loc[xs['stage'] == 'ttstar']\n",
    "plot = ggplot(ttstar, aes(x='config', y='runtime_ms')) \\\n",
    "    + geom_boxplot() \\\n",
    "    + geom_hline(yintercept=0, color='white') \\\n",
    "    + coord_flip() \\\n",
    "    + xlab('') + ylab('program runtime [ms]') \\\n",
    "    + ggtitle(\"TTstar runtime\")\n",
    "    \n",
    "print(plot)\n",
    "plot.save('ttstar-runtime.pdf', width=5.6, height=2.6, units='in')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sklearn.linear_model.LinearRegression()\n",
    "model.fit(\n",
    "    X=ttstar.loc[:, ('inference', 'verification', 'normalisation')],\n",
    "    y=ttstar['runtime_ms']\n",
    ")\n",
    "print('intercept =', model.intercept_)\n",
    "print('coefficients =', model.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smf.ols('runtime_ms ~ inference + verification + normalisation', data=ttstar).fit().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How much codegen time does erasure analysis save?\n",
    "\n",
    "The linear regression and the plot below give reassuring results:\n",
    "* erasure inference shaves about 2000 milliseconds off codegen time\n",
    "* typechecking has no statistically significant effect on codegen time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csc = xs.loc[xs['stage'] == 'csc']\n",
    "\n",
    "smf.ols('runtime_ms ~ inference + verification + normalisation', data=csc).fit().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = ggplot(csc, aes(x='config', y='runtime_ms')) \\\n",
    "    + geom_boxplot() \\\n",
    "    + geom_hline(yintercept=0, color='white') \\\n",
    "    + xlab('') + ylab('code generation time [ms]') \\\n",
    "    + coord_flip() \\\n",
    "    + ggtitle(\"Code generation\")\n",
    "    \n",
    "print(plot)\n",
    "plot.save('csc-runtime.pdf', width=5.6, height=2.6, units='in')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Runtime effect of erasure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exec = xs.loc[(xs['stage'] == 'execution') & ~xs['normalisation'] & ~xs['verification']]\n",
    "\n",
    "ggplot(exec.loc[exec['inference']], aes(x='input_size', y='runtime', color='config')) \\\n",
    "    + geom_point(alpha=0.3) \\\n",
    "    + ggtitle('Effect of compilation on erased programs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplot(exec.loc[exec['compilation'] == False],\n",
    "       aes(x='input_size', y='runtime_ms', color='config')) \\\n",
    "    + geom_point(alpha=0.3) \\\n",
    "    + facet_grid('. ~ inference', scales='free_x', labeller='label_both') \\\n",
    "    + xlab('input size') + ylab('runtime (s)') \\\n",
    "    + guides(color=False) # remove legend for colour\n",
    "    #ggtitle(\"Effect of erasure on interpreted programs\")\n",
    "#ggsave('exec-runtime-interpreted-erasure.pdf', width=5.6, height=3.0, units='in')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplot(exec.loc[exec['compilation'] == True],\n",
    "       aes(x='input_size', y='runtime_ms', color='config')) \\\n",
    "    + geom_point(alpha=0.3) \\\n",
    "    + facet_grid('. ~ inference', scales='free_x', labeller='label_both') \\\n",
    "    + xlab('input size') + ylab('runtime (s)') \\\n",
    "    + guides(color=False) # remove legend for colour\n",
    "\n",
    "#ggtitle(\"Effect of erasure on interpreted programs\")\n",
    "#ggsave('exec-runtime-interpreted-erasure.pdf', width=5.6, height=3.0, units='in')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplot(\n",
    "    exec.loc[\n",
    "        exec['compilation']\n",
    "        & ~exec['inference']\n",
    "        & (exec['input_size'] >= 32)\n",
    "    ],\n",
    "    aes(\n",
    "        x='np.log(runtime)',\n",
    "        y='np.log(input_size)')\n",
    ") \\\n",
    "    + geom_point()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smf.ols(\n",
    "    'np.log(runtime) ~ np.log(input_size)',\n",
    "    data=exec.loc[exec['compilation'] & ~exec['inference'] & (exec['input_size'] >= 32)],\n",
    ").fit().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplot(\n",
    "    exec.loc[\n",
    "        exec['compilation']\n",
    "        & exec['inference']\n",
    "        & (exec['input_size'] >= 32)\n",
    "    ],\n",
    "    aes(\n",
    "        x='np.log(runtime)',\n",
    "        y='np.log(input_size)')\n",
    ") \\\n",
    "    + geom_point()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smf.ols(\n",
    "    'np.log(runtime) ~ np.log(input_size)',\n",
    "    data=exec.loc[exec['compilation'] & exec['inference']],\n",
    ").fit().summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
